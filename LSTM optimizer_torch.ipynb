{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "# import multiprocessing\n",
    "import os.path\n",
    "import csv\n",
    "import copy\n",
    "# import joblib\n",
    "from torchvision import datasets\n",
    "import torchvision\n",
    "import seaborn as sns; sns.set(color_codes=True)\n",
    "sns.set_style(\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "def w(v):\n",
    "    if USE_CUDA:\n",
    "        return v.cuda()\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir -p _cache\n",
    "# cache = joblib.Memory(location='_cache', verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detach_var(v):\n",
    "    var = w(Variable(v.data, requires_grad=True))\n",
    "    var.retain_grad()\n",
    "    return var\n",
    "\n",
    "def do_fit(opt_net, meta_opt, target_cls, target_to_opt, unroll, optim_it, n_epochs, out_mul, should_train=True):\n",
    "    if should_train:\n",
    "        opt_net.train()\n",
    "    else:\n",
    "        opt_net.eval()\n",
    "        unroll = 1\n",
    "    \n",
    "    target = target_cls(training=should_train)\n",
    "    optimizee = w(target_to_opt())\n",
    "    n_params = 0\n",
    "    for p in optimizee.parameters():\n",
    "        n_params += int(np.prod(p.size()))\n",
    "    hidden_states = [w(Variable(torch.zeros(n_params, opt_net.hidden_sz))) for _ in range(2)]\n",
    "    cell_states = [w(Variable(torch.zeros(n_params, opt_net.hidden_sz))) for _ in range(2)]\n",
    "    all_losses_ever = []\n",
    "    if should_train:\n",
    "        meta_opt.zero_grad()\n",
    "    all_losses = None\n",
    "    for iteration in range(1, optim_it + 1):\n",
    "        loss = optimizee(target)\n",
    "                    \n",
    "        if all_losses is None:\n",
    "            all_losses = loss\n",
    "        else:\n",
    "            all_losses += loss\n",
    "        \n",
    "        all_losses_ever.append(loss.data.cpu().numpy())\n",
    "        loss.backward(retain_graph=should_train)\n",
    "\n",
    "        offset = 0\n",
    "        result_params = {}\n",
    "        hidden_states2 = [w(Variable(torch.zeros(n_params, opt_net.hidden_sz))) for _ in range(2)]\n",
    "        cell_states2 = [w(Variable(torch.zeros(n_params, opt_net.hidden_sz))) for _ in range(2)]\n",
    "        for name, p in optimizee.all_named_parameters():\n",
    "            cur_sz = int(np.prod(p.size()))\n",
    "            # We do this so the gradients are disconnected from the graph but we still get\n",
    "            # gradients from the rest\n",
    "            gradients = detach_var(p.grad.view(cur_sz, 1))\n",
    "            updates, new_hidden, new_cell = opt_net(\n",
    "                gradients,\n",
    "                [h[offset:offset+cur_sz] for h in hidden_states],\n",
    "                [c[offset:offset+cur_sz] for c in cell_states]\n",
    "            )\n",
    "            for i in range(len(new_hidden)):\n",
    "                hidden_states2[i][offset:offset+cur_sz] = new_hidden[i]\n",
    "                cell_states2[i][offset:offset+cur_sz] = new_cell[i]\n",
    "            result_params[name] = p + updates.view(*p.size()) * out_mul\n",
    "            result_params[name].retain_grad()\n",
    "            \n",
    "            offset += cur_sz\n",
    "            \n",
    "        if iteration % unroll == 0:\n",
    "            if should_train:\n",
    "                meta_opt.zero_grad()\n",
    "                all_losses.backward()\n",
    "                meta_opt.step()\n",
    "                \n",
    "            all_losses = None\n",
    "                        \n",
    "            optimizee = w(target_to_opt(**{k: detach_var(v) for k, v in result_params.items()}))\n",
    "            hidden_states = [detach_var(v) for v in hidden_states2]\n",
    "            cell_states = [detach_var(v) for v in cell_states2]\n",
    "            \n",
    "        else:\n",
    "            optimizee = w(target_to_opt(**result_params))\n",
    "            assert len(list(optimizee.all_named_parameters()))\n",
    "            hidden_states = hidden_states2\n",
    "            cell_states = cell_states2\n",
    "            \n",
    "    return all_losses_ever\n",
    "\n",
    "\n",
    "# @cache.cache\n",
    "def fit_optimizer(target_cls, target_to_opt, preproc=False, unroll=20, optim_it=100, n_epochs=20, n_tests=100, lr=0.001, out_mul=1.0):\n",
    "    opt_net = w(Optimizer(preproc=preproc))\n",
    "    meta_opt = optim.Adam(opt_net.parameters(), lr=lr)\n",
    "    \n",
    "    best_net = None\n",
    "    best_loss = 100000000000000000\n",
    "    \n",
    "    for _ in tqdm(range(n_epochs), 'epochs'):\n",
    "        for _ in tqdm(range(20), 'iterations'):\n",
    "            do_fit(opt_net, meta_opt, target_cls, target_to_opt, unroll, optim_it, n_epochs, out_mul, should_train=True)\n",
    "        \n",
    "        loss = (np.mean([\n",
    "            np.sum(do_fit(opt_net, meta_opt, target_cls, target_to_opt, unroll, optim_it, n_epochs, out_mul, should_train=False))\n",
    "            for _ in tqdm(range(n_tests), 'tests')\n",
    "        ]))\n",
    "        print(loss)\n",
    "        if loss < best_loss:\n",
    "            print(best_loss, loss)\n",
    "            best_loss = loss\n",
    "            best_net = copy.deepcopy(opt_net.state_dict())\n",
    "            \n",
    "    return best_loss, best_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuadraticLoss:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.W = w(Variable(torch.randn(10, 10)))\n",
    "        self.y = w(Variable(torch.randn(10)))\n",
    "        \n",
    "    def get_loss(self, theta):\n",
    "        return torch.sum((self.W.matmul(theta) - self.y)**2)\n",
    "    \n",
    "class QuadOptimizee(nn.Module):\n",
    "    def __init__(self, theta=None):\n",
    "        super().__init__()\n",
    "        # Note: assuming the same optimization for theta as for\n",
    "        # the function to find out itself.\n",
    "        if theta is None:\n",
    "            self.theta = nn.Parameter(torch.zeros(10))\n",
    "        else:\n",
    "            self.theta = theta\n",
    "        \n",
    "    def forward(self, target):\n",
    "        return target.get_loss(self.theta)\n",
    "    \n",
    "    def all_named_parameters(self):\n",
    "        return [('theta', self.theta)]\n",
    "        \n",
    "class Optimizer(nn.Module):\n",
    "    def __init__(self, preproc=False, hidden_sz=20, preproc_factor=10.0):\n",
    "        super().__init__()\n",
    "        self.hidden_sz = hidden_sz\n",
    "        if preproc:\n",
    "            self.recurs = nn.LSTMCell(2, hidden_sz)\n",
    "        else:\n",
    "            self.recurs = nn.LSTMCell(1, hidden_sz)\n",
    "        self.recurs2 = nn.LSTMCell(hidden_sz, hidden_sz)\n",
    "        self.output = nn.Linear(hidden_sz, 1)\n",
    "        self.preproc = preproc\n",
    "        self.preproc_factor = preproc_factor\n",
    "        self.preproc_threshold = np.exp(-preproc_factor)\n",
    "        \n",
    "    def forward(self, inp, hidden, cell):\n",
    "        if self.preproc:\n",
    "            # Implement preproc described in Appendix A\n",
    "            \n",
    "            # Note: we do all this work on tensors, which means\n",
    "            # the gradients won't propagate through inp. This\n",
    "            # should be ok because the algorithm involves\n",
    "            # making sure that inp is already detached.\n",
    "            inp = inp.data\n",
    "            inp2 = w(torch.zeros(inp.size()[0], 2))\n",
    "            keep_grads = (torch.abs(inp) >= self.preproc_threshold).squeeze()\n",
    "            inp2[:, 0][keep_grads] = (torch.log(torch.abs(inp[keep_grads]) + 1e-8) / self.preproc_factor).squeeze()\n",
    "            inp2[:, 1][keep_grads] = torch.sign(inp[keep_grads]).squeeze()\n",
    "            \n",
    "            inp2[:, 0][~keep_grads] = -1\n",
    "            inp2[:, 1][~keep_grads] = (float(np.exp(self.preproc_factor)) * inp[~keep_grads]).squeeze()\n",
    "            inp = w(Variable(inp2))\n",
    "        hidden0, cell0 = self.recurs(inp, (hidden[0], cell[0]))\n",
    "        hidden1, cell1 = self.recurs2(hidden0, (hidden[1], cell[1]))\n",
    "        return self.output(hidden1), (hidden0, hidden1), (cell0, cell1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b0bd58ed90e4ed2b190c14a4d18a519",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='all', max=11, style=ProgressStyle(description_width='initial'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying lr: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:86: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17beceed727c4814ad72d2a5d8ec6a90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epochs', max=20, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:87: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "984381daf547422ba4b732b3c0ea0324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='iterations', max=20, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:92: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ac6c2948680409888411627a0e6a310",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='tests', style=ProgressStyle(description_width='initial')), HT…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "137769.27\n",
      "100000000000000000 137769.27\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5170e076614e493fa4c2e465f973ccad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='iterations', max=20, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77c4a6adcc5540d9ad7b517e82ee3612",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='tests', style=ProgressStyle(description_width='initial')), HT…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "93914.48\n",
      "137769.27 93914.48\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "966471e319494be88f0d13ca99cc8acd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='iterations', max=20, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b4f879afb97497884ffcfc1302a0d43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='tests', style=ProgressStyle(description_width='initial')), HT…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-0dc8dcc52bf0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.03\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.003\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0003\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.00003\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.00001\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'all'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Trying lr:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQuadraticLoss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQuadOptimizee\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquad_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQuadraticLoss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQuadOptimizee\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.003\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-bb86afd33b35>\u001b[0m in \u001b[0;36mfit_optimizer\u001b[0;34m(target_cls, target_to_opt, preproc, unroll, optim_it, n_epochs, n_tests, lr, out_mul)\u001b[0m\n\u001b[1;32m     90\u001b[0m         loss = (np.mean([\n\u001b[1;32m     91\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_cls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_to_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munroll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim_it\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_mul\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshould_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_tests\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tests'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         ]))\n\u001b[1;32m     94\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-bb86afd33b35>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     90\u001b[0m         loss = (np.mean([\n\u001b[1;32m     91\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_cls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_to_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munroll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim_it\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_mul\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshould_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_tests\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tests'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         ]))\n\u001b[1;32m     94\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-bb86afd33b35>\u001b[0m in \u001b[0;36mdo_fit\u001b[0;34m(opt_net, meta_opt, target_cls, target_to_opt, unroll, optim_it, n_epochs, out_mul, should_train)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mall_losses\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mall_losses_ever\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshould_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for lr in tqdm([1.0, 0.3, 0.1, 0.03, 0.01, 0.003, 0.001, 0.0003, 0.0001, 0.00003, 0.00001], 'all'):\n",
    "    print('Trying lr:', lr)\n",
    "    print(fit_optimizer(QuadraticLoss, QuadOptimizee, lr=lr)[0])\n",
    "    \n",
    "loss, quad_optimizer = fit_optimizer(QuadraticLoss, QuadOptimizee, lr=0.003, n_epochs=100)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
